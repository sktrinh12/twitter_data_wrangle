{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangle report\n",
    "\n",
    "- In regards to the `twitter_archieved_enhanced.csv` file, it was simply loaded using the `pandas` library, and assessed in `jupyter notebook`. Some of the issues that stood out the most were: the `retweeted_status_id`, `retweeted_user_id`, `tweet_id`, `in_reply_to_status_id`, `in_reply_to_user_id` columns were not strings. Furthermore, the `retweeted_status_timestamp`column had to be changed to a `timestamp` datatype. A trailing '+0000' was removed as well. The `source` column was not used in analyzing the dataset, however it was cleaned by first removed the `<a>` html tags from the string, and then separated the url from the content into two new columns. Some of the dog names were invalid, they were simply words such as 'a' or 'the'. This was changed to NaN for the final cleaned dataset, however it was changed to 'None' for the visual dataset. The denominator was not always 10, so a simply arithmetic was used to make it 10 but adjust the numerator by that factor. This normalised the values and a one-number rating value was used to rank the dogs in the dataset. Prior to ranking, the values were changed to float datatype. Lastly, the `dog_stage` column was generated to include all the information described in the types of dog stages (doggo, pupper, puppo, fluffer). This was done by simply concatentating the strings from those respective columns. Extracting from the `text` column to double check that the dog stage was properly acquired was done before the concatentation. \n",
    "\n",
    "- The `image_predictions.csv` file did not have much cleaning to do. Simply casting the datatype from integer to string was done on the `tweet_id` column in order to merge with the `twitter_archived_enhanced.csv` dataset. Also, the dog names were changed to lowercase for consistency. For visualisation, the predicted dog and jpg url was used for displaying information for each dog in the interactive heatmap. \n",
    "\n",
    "- Finally, the `json_tweet.txt` file was generated using a slight modification of the provided python code. The data was then read into a pandas dataframe and only the `retweeted_count` and `favourite_count` values were extracted to merge with the main dataset. In the end all three cleaned/sliced datasets were merged (`df_merge`) into one main dataset and then filtered down to a smaller dataset to later be used for the heatmap visualisation (`plot_df`). The data was then saved into a `sqlite3` database for easy reading/writing. The two datasets, `df_merge` and `plot_df` are saved in a database file called `twitter_wrangle.db` into serparate tables titled, `clea_data_table` and `plot_data_table`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
